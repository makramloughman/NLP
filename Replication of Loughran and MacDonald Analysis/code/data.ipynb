{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad25d92",
   "metadata": {
    "id": "cad25d92"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "STPMNOm5Gf_U",
   "metadata": {
    "id": "STPMNOm5Gf_U"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13b806",
   "metadata": {
    "id": "5a13b806"
   },
   "source": [
    "## CIKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713067d7",
   "metadata": {
    "id": "713067d7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sp500_w_addl_id_with_cik.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df['date'] = pd.to_datetime(df['date'].to_list())\n",
    "df['start'] = pd.to_datetime(df['start'].to_list())\n",
    "df['ending'] = pd.to_datetime(df['ending'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6e1ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6ee6e1ab",
    "outputId": "e81af268-41d2-4b4f-e933-772aa3f05331"
   },
   "outputs": [],
   "source": [
    "tickers = df['ticker'].unique()\n",
    "tickers.sort()\n",
    "idmap = pd.concat([pd.DataFrame([df[df['ticker'] == tick].iloc[0]], columns=df.columns) for tick in tickers], ignore_index=True)\n",
    "idmap.drop(columns=['date', 'ret'], inplace=True)\n",
    "idmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb269b32",
   "metadata": {
    "id": "eb269b32"
   },
   "outputs": [],
   "source": [
    "cik_lookup = {}\n",
    "for index, row in idmap.iterrows():\n",
    "    cik_lookup[row['ticker']] = int(row['cik'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171ad25",
   "metadata": {
    "id": "4171ad25"
   },
   "source": [
    "## Get 10-Ks and 10-Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162c5bc",
   "metadata": {
    "id": "a162c5bc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V2DjzMuz6tD6",
   "metadata": {
    "id": "V2DjzMuz6tD6"
   },
   "outputs": [],
   "source": [
    "from ratelimit import limits, sleep_and_retry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6bde9e",
   "metadata": {
    "id": "1d6bde9e"
   },
   "source": [
    "### Get list of 10-Ks and 10-Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xeo6gFz56mAW",
   "metadata": {
    "id": "Xeo6gFz56mAW"
   },
   "outputs": [],
   "source": [
    "class SecAPI(object):\n",
    "    SEC_CALL_LIMIT = {'calls': 10, 'seconds': 1}\n",
    "    @staticmethod\n",
    "    @sleep_and_retry\n",
    "    @limits(calls=SEC_CALL_LIMIT['calls'] / 2, period=SEC_CALL_LIMIT['seconds'])\n",
    "    def _call_sec(url):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "        return requests.get(url, headers=headers)\n",
    "\n",
    "    def get(self, url):\n",
    "        return self._call_sec(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lkw2a9Q8p0P8",
   "metadata": {
    "id": "Lkw2a9Q8p0P8"
   },
   "outputs": [],
   "source": [
    "sec_api = SecAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62af4e9",
   "metadata": {
    "id": "c62af4e9"
   },
   "outputs": [],
   "source": [
    "def get_sec_entries(cik, doc_type, start=0, count=100, datea=20160101, dateb=20220101):\n",
    "    url = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany' \\\n",
    "        '&CIK={}&type={}&start={}&count={}&owner=exclude&datea={}&dateb={}&output=atom' \\\n",
    "        .format(cik, doc_type, start, count, datea, dateb)\n",
    "    sec_data = sec_api.get(url)\n",
    "    feed = BeautifulSoup(sec_data.encode('ascii'), 'xml').feed\n",
    "    entries = [(entry.content.find('filing-href').getText(),\n",
    "                entry.content.find('filing-type').getText(),\n",
    "                entry.content.find('filing-date').getText())\n",
    "                for entry in feed.find_all('entry', recursive=False)]\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6d73d",
   "metadata": {
    "id": "56b6d73d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sec_entries = {}\n",
    "for ticker, cik in tqdm(cik_lookup.items(), desc=f'Getting 10-K/Q entries per ticker', unit='ticker'):\n",
    "    sec_entries[ticker] = get_sec_entries(cik, '10-Q')\n",
    "    sec_entries[ticker] += get_sec_entries(cik, '10-K')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d58b5f",
   "metadata": {
    "id": "26d58b5f"
   },
   "source": [
    "### Download 10-Ks and 10-Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6f12a",
   "metadata": {
    "id": "efa6f12a"
   },
   "outputs": [],
   "source": [
    "def download_sec_data(sec_entries):\n",
    "    raw_fillings_by_ticker = {}\n",
    "    for ticker, data in sec_entries.items():\n",
    "        raw_fillings_by_ticker[ticker] = {}\n",
    "        for index_url, file_type, file_date in tqdm(data, desc='Downloading {} Fillings'.format(ticker), unit='filling'):\n",
    "            if (file_type == '10-K' or file_type == '10-Q'):\n",
    "                file_url = index_url.replace('-index.htm', '.txt').replace('.txtl', '.txt')            \n",
    "                raw_fillings_by_ticker[ticker][file_date] = sec_api.get(file_url)\n",
    "    return raw_fillings_by_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1303f52",
   "metadata": {
    "id": "b1303f52"
   },
   "outputs": [],
   "source": [
    "def get_documents(text):\n",
    "    extracted_docs = []\n",
    "    doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "    doc_end_pattern = re.compile(r'</DOCUMENT>')   \n",
    "    doc_start_is = [x.end() for x in doc_start_pattern.finditer(text)]\n",
    "    doc_end_is = [x.start() for x in doc_end_pattern.finditer(text)]\n",
    "    for doc_start_i, doc_end_i in zip(doc_start_is, doc_end_is):\n",
    "        extracted_docs.append(text[doc_start_i:doc_end_i])\n",
    "    return extracted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5db28f",
   "metadata": {
    "id": "1f5db28f"
   },
   "outputs": [],
   "source": [
    "def get_document_type(doc):\n",
    "    type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
    "    doc_type = type_pattern.findall(doc)[0][len('<TYPE>'):] \n",
    "    return doc_type.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f31162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_sequence(doc):\n",
    "    sequence_pattern = re.compile(r'<SEQUENCE>[^\\n]+')\n",
    "    doc_sequence = sequence_pattern.findall(doc)[0][len('<SEQUENCE>'):] \n",
    "    return doc_sequence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tuZZ_CxugEkW",
   "metadata": {
    "id": "tuZZ_CxugEkW"
   },
   "outputs": [],
   "source": [
    "def get_data(entries):\n",
    "    for ticker, data in entries.items():\n",
    "        raw_fillings_by_ticker = {}\n",
    "        for index_url, file_type, file_date in tqdm(data, desc='Downloading {} Fillings'.format(ticker), unit='filling'):\n",
    "            if (file_type == '10-K' or file_type == '10-Q'):\n",
    "                file_url = index_url.replace('-index.htm', '.txt').replace('.txtl', '.txt')            \n",
    "                raw_fillings_by_ticker[file_date] = sec_api.get(file_url)\n",
    "        filling_documents_by_ticker = {}\n",
    "        for file_date, filling in tqdm(raw_fillings_by_ticker.items(), desc='Getting Documents from {} Fillings'.format(ticker), unit='filling'):\n",
    "            filling_documents_by_ticker[file_date] = get_documents(filling)\n",
    "        ten_ks_by_ticker = []\n",
    "        for file_date, documents in filling_documents_by_ticker.items():\n",
    "            for document in documents:\n",
    "                document_type = get_document_type(document)\n",
    "                document_sequence = get_document_sequence(document)\n",
    "                if (document_type == '10-K' or document_type == '10-Q') and document_sequence == '1':\n",
    "                    ten_ks_by_ticker.append([document_type, file_date, document])\n",
    "        tmp = pd.DataFrame(data=ten_ks_by_ticker, columns=['type', 'date', 'file'])\n",
    "        tmp.to_csv(f'raw/{ticker}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EAxaywQOjuxs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "EAxaywQOjuxs",
    "outputId": "db809a44-7668-4336-9d04-f1270a25b348"
   },
   "outputs": [],
   "source": [
    "get_data(sec_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79f4cc",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48627cad",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ea1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = list(cik_lookup.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file(file):\n",
    "    body = BeautifulSoup(file.lower(), 'html.parser').get_text(separator=' ', strip=True)\n",
    "    tok = nltk.word_tokenize(body)\n",
    "    begin_doc = ['united', 'states', 'securities', 'and', 'exchange', 'commission']\n",
    "    for idx in range(len(tok) - len(begin_doc) + 1):\n",
    "        if tok[idx : idx + len(begin_doc)] == begin_doc:\n",
    "            break\n",
    "    if idx == len(tok) - len(begin_doc):\n",
    "        for idx in range(len(tok) - len(begin_doc[2:]) + 1):\n",
    "            if tok[idx : idx + len(begin_doc[2:])] == begin_doc[2:]:\n",
    "                break\n",
    "    alpha = []\n",
    "    for word in tok[idx:]:\n",
    "        if word.isalpha():\n",
    "            alpha.append(word)\n",
    "        else:\n",
    "            parts = word.split(\"'\")\n",
    "            bo = True\n",
    "            for part in parts:\n",
    "                if not part.isalpha():\n",
    "                    bo = False\n",
    "                    break\n",
    "            if bo:\n",
    "                alpha.append(word)\n",
    "    res = [word for word in alpha if word not in stopwords_list]\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e31ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean_data(tickers):\n",
    "    for ticker in tickers:\n",
    "        tmp = pd.read_csv(f'raw/{ticker}.csv')\n",
    "        start = pd.to_datetime(idmap[idmap['ticker'] == ticker]['start'].to_list()[0])\n",
    "        end = pd.to_datetime(idmap[idmap['ticker'] == ticker]['ending'].to_list()[0])\n",
    "        files = []\n",
    "        for i in tqdm(range(tmp.shape[0]), desc=f'Cleaning {ticker} 10-K/Qs', unit='file'):\n",
    "            if start <= pd.to_datetime(tmp.loc[i,'date']) <= end:\n",
    "                files.append([tmp.loc[i,'type'], tmp.loc[i,'date'], clean_file(tmp.loc[i,'file'])])\n",
    "        if len(files) > 0:\n",
    "            tmp2 = pd.DataFrame(data=files, columns=tmp.columns)\n",
    "            tmp2.to_csv(f'clean/{ticker}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(tickers)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
